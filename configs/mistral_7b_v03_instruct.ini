[parameters]
datasets = ["all"]
context_lengths = ["4k", "8k", "16k", "32k"]
max_context_length = 32768
model_path = mistralai/Mistral-7B-Instruct-v0.3
tokenizer_path = mistralai/Mistral-7B-Instruct-v0.3
device = cuda
model_torch_dtype = bfloat16
save_path = predictions/mistral_7b_v03_instr_32k.json
